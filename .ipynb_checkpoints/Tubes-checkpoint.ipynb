{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2044.8\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# open input video\n",
    "cap = cv2.VideoCapture('TestVid1.mp4')\n",
    "\n",
    "# Default resolutions of the frame are obtained.The default resolutions are system dependent.\n",
    "# We convert the resolutions from float to integer.\n",
    "frame_width = int(cap.get(3))\n",
    "frame_height = int(cap.get(4))\n",
    "\n",
    "# create video writer object to create output video\n",
    "out = cv2.VideoWriter('fgmask.avi',cv2.VideoWriter_fourcc('M','J','P','G'), 15, (frame_width,frame_height))\n",
    "\n",
    "# create background subtractor\n",
    "fgbg = cv2.createBackgroundSubtractorMOG2(detectShadows=True, history=100)\n",
    "\n",
    "# kernel for morphological operations\n",
    "kernel1 = np.ones((3,3),np.uint8)\n",
    "kernel2 = np.ones((9,9),np.uint8)\n",
    "\n",
    "threshold = frame_width * frame_height / 200\n",
    "print(threshold)\n",
    "\n",
    "while(1):\n",
    "    # read the frame\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if ret is True:\n",
    "\n",
    "        # apply the mask to the blurred frame\n",
    "        fgmask = fgbg.apply(frame)\n",
    "        \n",
    "        # remove shadow\n",
    "        fgmask[fgmask != 255] = 0\n",
    "        \n",
    "        cv2.imshow(\"fg\", fgmask)\n",
    "        \n",
    "        # apply blur to remove noise\n",
    "#         blur = cv2.GaussianBlur(fgmask, (5,5), 0)\n",
    "        \n",
    "#         cv2.imshow(\"blur\", blur)\n",
    "        \n",
    "        # remove small noise\n",
    "        img = cv2.morphologyEx(fgmask, cv2.MORPH_OPEN, kernel1)\n",
    "        img = cv2.morphologyEx(img, cv2.MORPH_OPEN, kernel1)\n",
    "        \n",
    "        \n",
    "        img = cv2.dilate(img,kernel2,iterations = 1)\n",
    "        \n",
    "        ########### COOOL\n",
    "        \n",
    "        \n",
    "        count, img = cv2.connectedComponents(img, connectivity=8)\n",
    "        \n",
    "        unique, count = np.unique(img, return_counts=True)\n",
    "        for i in range(0, len(count)):\n",
    "            if count[i] < threshold:\n",
    "                img[img == unique[i]] = 0\n",
    "                \n",
    "        img[img != 0] = 255\n",
    "        \n",
    "        img = img.astype(np.uint8)\n",
    "        \n",
    "        ############## END COOOL\n",
    "        \n",
    "        cv2.imshow(\"coool\", img)\n",
    "        \n",
    "        colorImg = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
    "        out.write(colorImg)\n",
    "            \n",
    "        k = cv2.waitKey(3) & 0xff\n",
    "        if k == 27:\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "    \n",
    "cap.release()\n",
    "out.release()\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found1\n",
      "tubelabel0\n",
      "(array([0, 1], dtype=uint8), array([405638,   3322], dtype=int64))\n",
      "[1]\n",
      "found2\n",
      "tubelabel1\n",
      "(array([0, 1, 2], dtype=uint8), array([400470,   5240,   3250], dtype=int64))\n",
      "[1, 2]\n",
      "found2\n",
      "tubelabel2\n",
      "(array([0, 1, 3], dtype=uint8), array([400836,   6026,   2098], dtype=int64))\n",
      "[1, 3]\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture('fgmask.avi')\n",
    "\n",
    "# Check if camera opened successfully\n",
    "if (cap.isOpened()== False): \n",
    "    print(\"Error opening video stream or file\")\n",
    "\n",
    "# Default resolutions of the frame are obtained.The default resolutions are system dependent.\n",
    "# We convert the resolutions from float to integer.\n",
    "frame_width = int(cap.get(3))\n",
    "frame_height = int(cap.get(4))\n",
    "\n",
    "out = cv2.VideoWriter('debug.avi',cv2.VideoWriter_fourcc('M','J','P','G'), 15, (frame_width,frame_height))\n",
    "\n",
    "# stores all labelled frames with tube labels\n",
    "volume = []\n",
    "labelList = []\n",
    "# number of labels in volume (aka number of tubes)\n",
    "tubeLabel = 0\n",
    "\n",
    "# count of OpenCV labels in previous frame\n",
    "oldCount = 1\n",
    "\n",
    "imgPrev = np.zeros((frame_width, frame_height),dtype=np.uint8)\n",
    "imgCurr = np.zeros((frame_width, frame_height),dtype=np.uint8)\n",
    "\n",
    "while(cap.isOpened()):\n",
    "        \n",
    "    # read the frame\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    \n",
    "    # frame is read properly\n",
    "    if ret is True:\n",
    "        \n",
    "        # fix JPEG compression issues\n",
    "        frame[frame>50] = 255\n",
    "        frame[frame!=255] = 0\n",
    "        \n",
    "        # Find connected components in the current image\n",
    "        count, labels = cv2.connectedComponents(cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY), connectivity=8)\n",
    "        \n",
    "        if count > 1:\n",
    "            \n",
    "            labels = labels.astype(np.uint8)\n",
    "            \n",
    "            label_hue = np.uint8(179*labels/np.max(labels))\n",
    "            blank_ch = 255*np.ones_like(label_hue)\n",
    "            labeled_img = cv2.merge([label_hue, blank_ch, blank_ch])\n",
    "            labeled_img = cv2.cvtColor(labeled_img, cv2.COLOR_HSV2BGR)\n",
    "            labeled_img[label_hue==0] = 0\n",
    "            \n",
    "            cv2.imshow('label', labeled_img)\n",
    "            out.write(labeled_img)\n",
    "        \n",
    "        # We need to match the components from current frame to component in previous frame\n",
    "        tempLabels = labels.copy()\n",
    "        tempList = []\n",
    "        # iterate through components in current frame\n",
    "        for i in range(1, count):\n",
    "            \n",
    "            # initially, no match is found wrt previous frame\n",
    "            match = 0\n",
    "            \n",
    "            # iterate through components in previous frame\n",
    "            for j in range(1, oldCount):\n",
    "                \n",
    "                imgCurr = labels.copy()\n",
    "                imgCurr[imgCurr!=i] = 0\n",
    "                imgCurr[imgCurr==i] = 255\n",
    "                \n",
    "#                 cv2.imshow(\"curr\", imgCurr)\n",
    "                \n",
    "                imgPrev = volume[-1].copy()\n",
    "                imgPrev[imgPrev!=labelList[-1][j-1]] = 0\n",
    "                imgPrev[imgPrev==labelList[-1][j-1]] = 255\n",
    "                \n",
    "#                 cv2.imshow(\"prev\", imgPrev)\n",
    "                \n",
    "                # multiply masks to find intersections of components\n",
    "                prod = imgPrev/255 * imgCurr/255\n",
    "                \n",
    "                # product is black if there is no intersection\n",
    "                # sum all the pixels\n",
    "                total = np.sum(prod)\n",
    "                if total/(np.sum(imgPrev/255)) > 0.5:\n",
    "                    match = labelList[-1][j-1]\n",
    "                    break\n",
    "                    \n",
    "            # match found for the selected component\n",
    "            if match is not 0:\n",
    "                # renaming selected component with matched component label\n",
    "                tempLabels[labels==i] = labelList[-1][j-1]\n",
    "                tempList.append(labelList[-1][j-1])\n",
    "                \n",
    "#                 print(\"Match\")\n",
    "#                 print(tempList)\n",
    "#                 print(np.unique(tempLabels, return_counts=True))\n",
    "            else:\n",
    "                # new component found\n",
    "                print(\"found\" + str(i))\n",
    "                print(\"tubelabel\" + str(tubeLabel))\n",
    "#                 print(np.unique(tempLabels, return_counts=True))\n",
    "                tubeLabel += 1\n",
    "                tempLabels[labels==i] = tubeLabel\n",
    "                print(np.unique(tempLabels, return_counts=True))\n",
    "                tempList.append(tubeLabel)\n",
    "                \n",
    "                print(tempList)\n",
    "            \n",
    "        volume.append(tempLabels)\n",
    "        labelList.append(tempList)\n",
    "        oldCount = count\n",
    "        \n",
    "        k = cv2.waitKey(0) & 0xff\n",
    "        if k == 27:\n",
    "            break\n",
    "        \n",
    "    # frame is not read properly\n",
    "    else:\n",
    "        break\n",
    "    \n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(305, 480, 852)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(volume))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = volume[350]\n",
    "x[x!=0] = 255\n",
    "cv2.imshow('vol', x)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intersection True{1: [1, 1], 2: [1, 1]}\n",
      "intersection True{1: [2, 2], 2: [2, 2]}\n",
      "intersection True{1: [3, 3], 2: [3, 3]}\n",
      "intersection True{1: [4, 4], 2: []}\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "def binary_mask(img, val, replacement_val):\n",
    "    \"\"\"\n",
    "    Create a binary mask of the image\n",
    "\n",
    "    Args:\n",
    "        img: An image to be masked\n",
    "        val: The value in the image to be masked\n",
    "        replacement_val: The high value to be used in the binary mask\n",
    "\n",
    "    Returns: Nothing. Masking is performed in-place.\n",
    "    \"\"\"\n",
    "\n",
    "    img[img != val] = 0 # Pixels not equal to the required value are made 0\n",
    "    img[img == val] = replacement_val # Pixels equal to the required value are set to replacement value\n",
    "    return\n",
    "\n",
    "def open_video(filename):\n",
    "    \"\"\"\n",
    "    Open a video file using VideoCapture object\n",
    "\n",
    "    Args:\n",
    "        filename: The name of the file to be opened\n",
    "            Pass 0 to open webcam, or -1 to search for cameras\n",
    "\n",
    "    Raises:\n",
    "        IOError: If the file or stream cannot be opened\n",
    "\n",
    "    Returns: VideoCapture object, frame width, frame hight\n",
    "    \"\"\"\n",
    "\n",
    "    cap = cv2.VideoCapture(filename) # Init VideoCapture object\n",
    "\n",
    "    frame_width = frame_height = 0\n",
    "\n",
    "    # Check if camera opened successfully\n",
    "    if cap.isOpened() is False:\n",
    "        raise IOError('Error opening video stream or file.')\n",
    "    else:\n",
    "        # Default resolutions of the frame are obtained.\n",
    "        # We convert the resolutions from float to integer.\n",
    "        frame_width = int(cap.get(3))\n",
    "        frame_height = int(cap.get(4))\n",
    "\n",
    "    return cap, frame_width, frame_height\n",
    "\n",
    "def intersecting_regions(cur_img, cur_count, prev_img, prev_labels,\n",
    "                            intersection_threshold = 0.2):\n",
    "\n",
    "    \"\"\"\n",
    "    Find the number of intersecting regions between the any region in the\n",
    "    current image and any regions in the previous image\n",
    "\n",
    "    Args:\n",
    "        cur_img: The labelled image of the current frame returned by OpenCV\n",
    "            Connected Components\n",
    "\n",
    "        cur_count: Number of components in cur_img\n",
    "\n",
    "        prev_img: The labelled image of the previous frame returned by OpenCV\n",
    "            Connected Components\n",
    "\n",
    "        prev_labels: The tube labels present in the prev_img\n",
    "\n",
    "        intersection_threshold: Fraction of intersection between regions in\n",
    "        previous and current image\n",
    "\n",
    "    Returns: A dict mapping intersecting regions in current frame to regions in\n",
    "        the previous frame\n",
    "            Example:\n",
    "                {\n",
    "                    2 : [2, 3],\n",
    "                    3 : [4]\n",
    "                }\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    # Create a copy of the images to prevent overwriting the parameters\n",
    "    prev_img = prev_img.copy()\n",
    "    cur_img = cur_img.copy()\n",
    "\n",
    "    match_dict = {} # Dictionary to store the intersecting regions\n",
    "\n",
    "    # Stores whether any current region intersect with multiple previous regions\n",
    "    multiple_intersections = False\n",
    "\n",
    "    for region_cur in range(1, cur_count):\n",
    "\n",
    "        # Create a copy of the image for this iteration\n",
    "        cur_img_copy = cur_img.copy()\n",
    "        binary_mask(cur_img_copy, region_cur, 1)\n",
    "\n",
    "        matches = [] # Clear matches list for each region in current image\n",
    "\n",
    "        for region_prev in prev_labels:\n",
    "\n",
    "            # Create a copy of the image for this iteration\n",
    "            prev_img_copy = prev_img.copy()\n",
    "            binary_mask(prev_img_copy, region_prev, 1)\n",
    "\n",
    "            # Multiply masks to find the intersections of regions\n",
    "            intersection = prev_img_copy * cur_img_copy\n",
    "\n",
    "            # Number of intersecting pixels\n",
    "            intersection_count = np.sum(intersection)\n",
    "\n",
    "            # Number of pixels in previous region\n",
    "            region_prev_count = np.sum(prev_img_copy)\n",
    "\n",
    "            # Region is matched if intersection fraction greater than threshold\n",
    "            if intersection_count/region_prev_count > intersection_threshold:\n",
    "                matches.append(region_prev)\n",
    "\n",
    "        if len(matches) > 1:\n",
    "            multiple_intersections = True\n",
    "\n",
    "        match_dict[region_cur] = matches\n",
    "\n",
    "    return multiple_intersections, match_dict\n",
    "\n",
    "\n",
    "\n",
    "try:\n",
    "    cap, frame_width, frame_height = open_video('fgmask.avi')\n",
    "except IOError as error:\n",
    "    print(error)\n",
    "    print('Check the filename or camera.')\n",
    "    \n",
    "volume = [np.zeros((frame_height, frame_width), dtype=np.uint8)] # 3D volume; A list for storing the labelled images\n",
    "labels = [[1]] # A list storing the tube labels in each image in the volume\n",
    "tube_num = 0 # Number of tubes found\n",
    "prev_count = 1 # OpenCV returns at least 1 label (i.e. the background)\n",
    "\n",
    "overwrite_dict = {}\n",
    "\n",
    "out = cv2.VideoWriter('debug.avi', cv2.VideoWriter_fourcc('M', 'J', 'P', 'G'),\n",
    "                        15, (frame_width,frame_height))\n",
    "\n",
    "while(cap.isOpened()):\n",
    "    ret, frame = cap.read() # Read the frame\n",
    "\n",
    "    if ret is False: # Frame is read properly\n",
    "        break\n",
    "\n",
    "    # Fix JPEG compression issues\n",
    "    frame[frame>50] = 255\n",
    "    frame[frame!=255] = 0\n",
    "\n",
    "    # Find connected components in the current image\n",
    "    cur_count, cur_img = cv2.connectedComponents(cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY), connectivity=8)\n",
    "\n",
    "    ###############################################################\n",
    "    # Debug output of connected components\n",
    "    if cur_count > 1:\n",
    "\n",
    "        cur_img = cur_img.astype(np.uint8)\n",
    "\n",
    "        label_hue = np.uint8(179*cur_img/np.max(cur_img))\n",
    "        blank_ch = 255*np.ones_like(label_hue)\n",
    "        labeled_img = cv2.merge([label_hue, blank_ch, blank_ch])\n",
    "        labeled_img = cv2.cvtColor(labeled_img, cv2.COLOR_HSV2BGR)\n",
    "        labeled_img[label_hue==0] = 0\n",
    "\n",
    "        cv2.imshow('label', labeled_img)\n",
    "        out.write(labeled_img)\n",
    "    ###############################################################\n",
    "\n",
    "    ret, match_dict = intersecting_regions(cur_img, cur_count, volume[-1], labels[-1])\n",
    "\n",
    "    cur_label = []\n",
    "\n",
    "    cur_img_output = cur_img.copy()\n",
    "\n",
    "    if ret is True:\n",
    "        # Some current region is intersecting with multiple previous regions\n",
    "\n",
    "        cur_img_copy = cur_img.copy()\n",
    "\n",
    "        # Erode the image to try and separate the regions\n",
    "        kernel = np.ones((3,3), np.uint8)\n",
    "        cur_img_copy = cv2.erode(cur_img_copy, kernel, iterations = 1)\n",
    "\n",
    "        cur_count_copy, cur_img_copy = cv2.connectedComponents(cur_img_copy, connectivity=8)\n",
    "\n",
    "        # Find the number of intersections using eroded image\n",
    "        ret, match_dict_copy = intersecting_regions(cur_img_copy, cur_count_copy, volume[-1], labels[-1])\n",
    "\n",
    "\n",
    "        print(\"intersection \" + str(ret) + str(match_dict_copy))\n",
    "\n",
    "        if ret is False:\n",
    "            print(\"erosion success\")\n",
    "            # The intersecting regions have been separated by erosion\n",
    "            # Replace the image by the eroded image\n",
    "            cur_img = cur_img_copy\n",
    "            cur_count = cur_count_copy\n",
    "            match_dict = match_dict_copy\n",
    "        else:\n",
    "            # The intersecting regions did not separate\n",
    "            # Overwrite matching labels in the volume with current label\n",
    "\n",
    "            tube_num += 1\n",
    "\n",
    "            for region in match_dict:\n",
    "                if len(match_dict[region]) > 1:\n",
    "\n",
    "                    for index in match_dict[region]:\n",
    "                        for frame in volume:\n",
    "                            # Update labels of tubes in previous frame\n",
    "                            frame[frame == index] = tube_num\n",
    "                            # Add an entry to the overwrite dict\n",
    "                            overwrite_dict[index] = [tube_num]\n",
    "\n",
    "                    # Update the dict\n",
    "                    match_dict[region] = [tube_num]\n",
    "#                     cur_img[cur_img == region] = tube_num\n",
    "#                     cur_label.append(tube_num)\n",
    "\n",
    "                    \n",
    "\n",
    "\n",
    "    # There are no intersection issues; Proceed normally\n",
    "    for region in match_dict:\n",
    "        if len(match_dict[region]) == 0:\n",
    "            # New region found since there is no match to any previous region\n",
    "            tube_num += 1\n",
    "            cur_img_output[cur_img == region] = tube_num\n",
    "            cur_label.append(tube_num)\n",
    "\n",
    "        else:\n",
    "            # Some previous region was found, relabel the region\n",
    "            cur_img_output[cur_img == region] = match_dict[region][0]\n",
    "            cur_label.append(match_dict[region][0])\n",
    "    \n",
    "\n",
    "    volume.append(cur_img_output)\n",
    "#     print(cur_label)\n",
    "    labels.append(cur_label) # Convert keys in the match_dict to a list of labels of current image\n",
    "    prev_count = cur_count\n",
    "\n",
    "    k = cv2.waitKey(1) & 0xff\n",
    "    if k == 27:\n",
    "        break\n",
    "\n",
    "# Update previous frames\n",
    "# print(overwrite_dict)\n",
    "# for index in overwrite_dict:\n",
    "#     for frame in volume:\n",
    "#         # Update labels of tubes in previous frame\n",
    "#         frame[frame == index] = tube_num\n",
    "    \n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n",
    "print('done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tube_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 5 6]\n",
      "[185363359    655793    875568]\n"
     ]
    }
   ],
   "source": [
    "uniq, __ = np.unique(volume, return_counts=True)\n",
    "print(uniq)\n",
    "print(__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(0, len(uniq)):\n",
    "    \n",
    "    out = cv2.VideoWriter('maskTube{0}.avi'.format(i),cv2.VideoWriter_fourcc('M','J','P','G'), 15, (frame_width,frame_height))\n",
    "    \n",
    "    for frame in volume:\n",
    "        frameCopy = frame.copy()\n",
    "        frameCopy[frameCopy==uniq[i]] = 255\n",
    "        frameCopy[frameCopy!=255] = 0\n",
    "        frameCopy = frameCopy.astype(np.uint8)\n",
    "        out.write(cv2.cvtColor(frameCopy, cv2.COLOR_GRAY2BGR))\n",
    "\n",
    "    out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.savez_compressed('volume.npz', a=volume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.savez('volume2.npz', a=volume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loaded = np.load('volume.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "np.savez_compressed('vol', a=volume)\n",
    "loaded = np.load('vol.npz')\n",
    "print(np.array_equal(volume, loaded['a']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(457, 480, 852)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(np.array(loaded['a']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hd = np.zeros((900, 1920, 1080), dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.5705693"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e1 = cv2.getTickCount()\n",
    "\n",
    "out = cv2.VideoWriter('vol2.mp4',cv2.VideoWriter_fourcc('X','V','I','D'), 60, (frame_width,frame_height))\n",
    "\n",
    "cap = cv2.VideoCapture('vol.mp4')\n",
    "while(cap.isOpened()):\n",
    "    # read the frame\n",
    "    ret, frame = cap.read()\n",
    "    # frame is read properly\n",
    "    if ret is True:\n",
    "        out.write(frame)\n",
    "    else:\n",
    "        break\n",
    "cap.release()\n",
    "out.release()\n",
    "\n",
    "\n",
    "e2 = cv2.getTickCount()\n",
    "time = (e2 - e1)/ cv2.getTickFrequency()\n",
    "time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'dtype'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-198-3686fac568ee>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mvol\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'dtype'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.savez_compressed('vol', a=vol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.7602012"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e1 = cv2.getTickCount()\n",
    "\n",
    "loaded = np.load('vol.npz')\n",
    "loaded['a'].dtype\n",
    "\n",
    "e2 = cv2.getTickCount()\n",
    "time = (e2 - e1)/ cv2.getTickFrequency()\n",
    "time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(305, 480, 852, 3)"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
