{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2044.8\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# open input video\n",
    "cap = cv2.VideoCapture('TestVid3.mp4')\n",
    "\n",
    "# Default resolutions of the frame are obtained.The default resolutions are system dependent.\n",
    "# We convert the resolutions from float to integer.\n",
    "frame_width = int(cap.get(3))\n",
    "frame_height = int(cap.get(4))\n",
    "\n",
    "# create video writer object to create output video\n",
    "out = cv2.VideoWriter('fgmask.avi',cv2.VideoWriter_fourcc('M','J','P','G'), 15, (frame_width,frame_height))\n",
    "\n",
    "# create background subtractor\n",
    "fgbg = cv2.createBackgroundSubtractorMOG2(detectShadows=True, history=100)\n",
    "\n",
    "# kernel for morphological operations\n",
    "kernel1 = np.ones((3,3),np.uint8)\n",
    "kernel2 = np.ones((9,9),np.uint8)\n",
    "\n",
    "threshold = frame_width * frame_height / 200\n",
    "print(threshold)\n",
    "\n",
    "while(1):\n",
    "    # read the frame\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if ret is True:\n",
    "\n",
    "        # apply the mask to the blurred frame\n",
    "        fgmask = fgbg.apply(frame)\n",
    "        \n",
    "        # remove shadow\n",
    "        fgmask[fgmask != 255] = 0\n",
    "        \n",
    "        cv2.imshow(\"fg\", fgmask)\n",
    "        \n",
    "        # apply blur to remove noise\n",
    "#         blur = cv2.GaussianBlur(fgmask, (5,5), 0)\n",
    "        \n",
    "#         cv2.imshow(\"blur\", blur)\n",
    "        \n",
    "        # remove small noise\n",
    "        img = cv2.morphologyEx(fgmask, cv2.MORPH_OPEN, kernel1)\n",
    "        img = cv2.morphologyEx(img, cv2.MORPH_OPEN, kernel1)\n",
    "        \n",
    "        \n",
    "        img = cv2.dilate(img,kernel2,iterations = 1)\n",
    "        \n",
    "        ########### COOOL\n",
    "        \n",
    "        \n",
    "        count, img = cv2.connectedComponents(img, connectivity=8)\n",
    "        \n",
    "        unique, count = np.unique(img, return_counts=True)\n",
    "        for i in range(0, len(count)):\n",
    "            if count[i] < threshold:\n",
    "                img[img == unique[i]] = 0\n",
    "                \n",
    "        img[img != 0] = 255\n",
    "        \n",
    "        img = img.astype(np.uint8)\n",
    "        \n",
    "        ############## END COOOL\n",
    "        \n",
    "        cv2.imshow(\"coool\", img)\n",
    "        \n",
    "        colorImg = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
    "        out.write(colorImg)\n",
    "            \n",
    "        k = cv2.waitKey(3) & 0xff\n",
    "        if k == 27:\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "    \n",
    "cap.release()\n",
    "out.release()\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found1\n",
      "tubelabel0\n",
      "(array([0, 1], dtype=uint8), array([406848,   2112], dtype=int64))\n",
      "[1]\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture('fgmask.avi')\n",
    "\n",
    "# Check if camera opened successfully\n",
    "if (cap.isOpened()== False): \n",
    "    print(\"Error opening video stream or file\")\n",
    "\n",
    "# Default resolutions of the frame are obtained.The default resolutions are system dependent.\n",
    "# We convert the resolutions from float to integer.\n",
    "frame_width = int(cap.get(3))\n",
    "frame_height = int(cap.get(4))\n",
    "\n",
    "out = cv2.VideoWriter('debug.avi',cv2.VideoWriter_fourcc('M','J','P','G'), 15, (frame_width,frame_height))\n",
    "\n",
    "# stores all labelled frames with tube labels\n",
    "volume = []\n",
    "labelList = []\n",
    "# number of labels in volume (aka number of tubes)\n",
    "tubeLabel = 0\n",
    "\n",
    "# count of OpenCV labels in previous frame\n",
    "oldCount = 1\n",
    "\n",
    "imgPrev = np.zeros((frame_width, frame_height),dtype=np.uint8)\n",
    "imgCurr = np.zeros((frame_width, frame_height),dtype=np.uint8)\n",
    "\n",
    "while(cap.isOpened()):\n",
    "        \n",
    "    # read the frame\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    \n",
    "    # frame is read properly\n",
    "    if ret is True:\n",
    "        \n",
    "        # fix JPEG compression issues\n",
    "        frame[frame>50] = 255\n",
    "        frame[frame!=255] = 0\n",
    "        \n",
    "        # Find connected components in the current image\n",
    "        count, labels = cv2.connectedComponents(cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY), connectivity=8)\n",
    "        \n",
    "        if count > 1:\n",
    "            \n",
    "            labels = labels.astype(np.uint8)\n",
    "            \n",
    "            label_hue = np.uint8(179*labels/np.max(labels))\n",
    "            blank_ch = 255*np.ones_like(label_hue)\n",
    "            labeled_img = cv2.merge([label_hue, blank_ch, blank_ch])\n",
    "            labeled_img = cv2.cvtColor(labeled_img, cv2.COLOR_HSV2BGR)\n",
    "            labeled_img[label_hue==0] = 0\n",
    "            \n",
    "            cv2.imshow('label', labeled_img)\n",
    "            out.write(labeled_img)\n",
    "        \n",
    "        # We need to match the components from current frame to component in previous frame\n",
    "        tempLabels = labels.copy()\n",
    "        tempList = []\n",
    "        # iterate through components in current frame\n",
    "        for i in range(1, count):\n",
    "            \n",
    "            # initially, no match is found wrt previous frame\n",
    "            match = 0\n",
    "            \n",
    "            # iterate through components in previous frame\n",
    "            for j in range(1, oldCount):\n",
    "                \n",
    "                imgCurr = labels.copy()\n",
    "                imgCurr[imgCurr!=i] = 0\n",
    "                imgCurr[imgCurr==i] = 255\n",
    "                \n",
    "#                 cv2.imshow(\"curr\", imgCurr)\n",
    "                \n",
    "                imgPrev = volume[-1].copy()\n",
    "                imgPrev[imgPrev!=labelList[-1][j-1]] = 0\n",
    "                imgPrev[imgPrev==labelList[-1][j-1]] = 255\n",
    "                \n",
    "#                 cv2.imshow(\"prev\", imgPrev)\n",
    "                \n",
    "                # multiply masks to find intersections of components\n",
    "                prod = imgPrev/255 * imgCurr/255\n",
    "                \n",
    "                # product is black if there is no intersection\n",
    "                # sum all the pixels\n",
    "                total = np.sum(prod)\n",
    "                if total/(np.sum(imgPrev/255)) > 0.5:\n",
    "                    match = labelList[-1][j-1]\n",
    "                    break\n",
    "                    \n",
    "            # match found for the selected component\n",
    "            if match is not 0:\n",
    "                # renaming selected component with matched component label\n",
    "                tempLabels[labels==i] = labelList[-1][j-1]\n",
    "                tempList.append(labelList[-1][j-1])\n",
    "                \n",
    "#                 print(\"Match\")\n",
    "#                 print(tempList)\n",
    "#                 print(np.unique(tempLabels, return_counts=True))\n",
    "            else:\n",
    "                # new component found\n",
    "                print(\"found\" + str(i))\n",
    "                print(\"tubelabel\" + str(tubeLabel))\n",
    "#                 print(np.unique(tempLabels, return_counts=True))\n",
    "                tubeLabel += 1\n",
    "                tempLabels[labels==i] = tubeLabel\n",
    "                print(np.unique(tempLabels, return_counts=True))\n",
    "                tempList.append(tubeLabel)\n",
    "                \n",
    "                print(tempList)\n",
    "            \n",
    "        volume.append(tempLabels)\n",
    "        labelList.append(tempList)\n",
    "        oldCount = count\n",
    "        \n",
    "        k = cv2.waitKey(0) & 0xff\n",
    "        if k == 27:\n",
    "            break\n",
    "        \n",
    "    # frame is not read properly\n",
    "    else:\n",
    "        break\n",
    "    \n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(305, 480, 852)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(volume))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = volume[350]\n",
    "x[x!=0] = 255\n",
    "cv2.imshow('vol', x)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intersection True{1: [1], 2: [2, 2], 3: [2, 2]}\n",
      "intersection True{1: [1], 2: [3, 3], 3: [3, 3]}\n",
      "intersection True{1: [1], 2: [4, 4], 3: [4, 4]}\n",
      "intersection True{1: [1], 2: [5, 5], 3: [5, 5]}\n",
      "intersection True{1: [1], 2: [6, 6]}\n",
      "intersection False{1: [1], 2: [7]}\n",
      "erosion success\n",
      "intersection True{1: [1, 7]}\n",
      "intersection True{1: [8, 8], 2: [8, 8]}\n",
      "intersection True{1: [9, 9], 2: [9, 9]}\n",
      "intersection True{1: [10, 10], 2: [10, 10]}\n",
      "intersection True{1: [11, 11], 2: [11, 11]}\n",
      "intersection True{1: [12, 12], 2: [12, 12]}\n",
      "intersection True{1: [13, 13], 2: [13, 13]}\n",
      "intersection True{1: [14, 14], 2: [14, 14]}\n",
      "intersection True{1: [15, 15], 2: [15, 15]}\n",
      "intersection True{1: [16, 16], 2: [16, 16]}\n",
      "intersection True{1: [17, 17], 2: [17, 17]}\n",
      "intersection True{1: [18, 18], 2: [18, 18]}\n",
      "intersection True{1: [19, 19]}\n",
      "{2: [3], 3: [4], 4: [5], 5: [6], 6: [7], 1: [8], 7: [8], 8: [9], 9: [10], 10: [11], 11: [12], 12: [13], 13: [14], 14: [15], 15: [16], 16: [17], 17: [18], 18: [19], 19: [20]}\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "def binary_mask(img, val, replacement_val):\n",
    "    \"\"\"\n",
    "    Create a binary mask of the image\n",
    "\n",
    "    Args:\n",
    "        img: An image to be masked\n",
    "        val: The value in the image to be masked\n",
    "        replacement_val: The high value to be used in the binary mask\n",
    "\n",
    "    Returns: Nothing. Masking is performed in-place.\n",
    "    \"\"\"\n",
    "\n",
    "    img[img != val] = 0 # Pixels not equal to the required value are made 0\n",
    "    img[img == val] = replacement_val # Pixels equal to the required value are set to replacement value\n",
    "    return\n",
    "\n",
    "def open_video(filename):\n",
    "    \"\"\"\n",
    "    Open a video file using VideoCapture object\n",
    "\n",
    "    Args:\n",
    "        filename: The name of the file to be opened\n",
    "            Pass 0 to open webcam, or -1 to search for cameras\n",
    "\n",
    "    Raises:\n",
    "        IOError: If the file or stream cannot be opened\n",
    "\n",
    "    Returns: VideoCapture object, frame width, frame hight\n",
    "    \"\"\"\n",
    "\n",
    "    cap = cv2.VideoCapture(filename) # Init VideoCapture object\n",
    "\n",
    "    frame_width = frame_height = 0\n",
    "\n",
    "    # Check if camera opened successfully\n",
    "    if cap.isOpened() is False:\n",
    "        raise IOError('Error opening video stream or file.')\n",
    "    else:\n",
    "        # Default resolutions of the frame are obtained.\n",
    "        # We convert the resolutions from float to integer.\n",
    "        frame_width = int(cap.get(3))\n",
    "        frame_height = int(cap.get(4))\n",
    "\n",
    "    return cap, frame_width, frame_height\n",
    "\n",
    "def intersecting_regions(cur_img, cur_count, prev_img, prev_labels,\n",
    "                            intersection_threshold = 0.2):\n",
    "\n",
    "    \"\"\"\n",
    "    Find the number of intersecting regions between the any region in the\n",
    "    current image and any regions in the previous image\n",
    "\n",
    "    Args:\n",
    "        cur_img: The labelled image of the current frame returned by OpenCV\n",
    "            Connected Components\n",
    "\n",
    "        cur_count: Number of components in cur_img\n",
    "\n",
    "        prev_img: The labelled image of the previous frame returned by OpenCV\n",
    "            Connected Components\n",
    "\n",
    "        prev_labels: The tube labels present in the prev_img\n",
    "\n",
    "        intersection_threshold: Fraction of intersection between regions in\n",
    "        previous and current image\n",
    "\n",
    "    Returns: A dict mapping intersecting regions in current frame to regions in\n",
    "        the previous frame\n",
    "            Example:\n",
    "                {\n",
    "                    2 : [2, 3],\n",
    "                    3 : [4]\n",
    "                }\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    # Create a copy of the images to prevent overwriting the parameters\n",
    "    prev_img = prev_img.copy()\n",
    "    cur_img = cur_img.copy()\n",
    "\n",
    "    match_dict = {} # Dictionary to store the intersecting regions\n",
    "\n",
    "    # Stores whether any current region intersect with multiple previous regions\n",
    "    multiple_intersections = False\n",
    "\n",
    "    for region_cur in range(1, cur_count):\n",
    "\n",
    "        # Create a copy of the image for this iteration\n",
    "        cur_img_copy = cur_img.copy()\n",
    "        binary_mask(cur_img_copy, region_cur, 1)\n",
    "\n",
    "        matches = [] # Clear matches list for each region in current image\n",
    "\n",
    "        for region_prev in prev_labels:\n",
    "\n",
    "            # Create a copy of the image for this iteration\n",
    "            prev_img_copy = prev_img.copy()\n",
    "            binary_mask(prev_img_copy, region_prev, 1)\n",
    "\n",
    "            # Multiply masks to find the intersections of regions\n",
    "            intersection = prev_img_copy * cur_img_copy\n",
    "\n",
    "            # Number of intersecting pixels\n",
    "            intersection_count = np.sum(intersection)\n",
    "\n",
    "            # Number of pixels in previous region\n",
    "            region_prev_count = np.sum(prev_img_copy)\n",
    "\n",
    "            # Region is matched if intersection fraction greater than threshold\n",
    "            if intersection_count/region_prev_count > intersection_threshold:\n",
    "                matches.append(region_prev)\n",
    "\n",
    "        if len(matches) > 1:\n",
    "            multiple_intersections = True\n",
    "\n",
    "        match_dict[region_cur] = matches\n",
    "\n",
    "    return multiple_intersections, match_dict\n",
    "\n",
    "\n",
    "\n",
    "try:\n",
    "    cap, frame_width, frame_height = open_video('fgmask.avi')\n",
    "except IOError as error:\n",
    "    print(error)\n",
    "    print('Check the filename or camera.')\n",
    "    \n",
    "volume = [np.zeros((frame_height, frame_width), dtype=np.uint8)] # 3D volume; A list for storing the labelled images\n",
    "labels = [[1]] # A list storing the tube labels in each image in the volume\n",
    "tube_num = 0 # Number of tubes found\n",
    "prev_count = 1 # OpenCV returns at least 1 label (i.e. the background)\n",
    "\n",
    "overwrite_dict = {}\n",
    "\n",
    "out = cv2.VideoWriter('debug.avi', cv2.VideoWriter_fourcc('M', 'J', 'P', 'G'),\n",
    "                        15, (frame_width,frame_height))\n",
    "\n",
    "while(cap.isOpened()):\n",
    "    ret, frame = cap.read() # Read the frame\n",
    "\n",
    "    if ret is False: # Frame is read properly\n",
    "        break\n",
    "\n",
    "    # Fix JPEG compression issues\n",
    "    frame[frame>50] = 255\n",
    "    frame[frame!=255] = 0\n",
    "\n",
    "    # Find connected components in the current image\n",
    "    cur_count, cur_img = cv2.connectedComponents(cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY), connectivity=8)\n",
    "\n",
    "    ###############################################################\n",
    "    # Debug output of connected components\n",
    "    if cur_count > 1:\n",
    "\n",
    "        cur_img = cur_img.astype(np.uint8)\n",
    "\n",
    "        label_hue = np.uint8(179*cur_img/np.max(cur_img))\n",
    "        blank_ch = 255*np.ones_like(label_hue)\n",
    "        labeled_img = cv2.merge([label_hue, blank_ch, blank_ch])\n",
    "        labeled_img = cv2.cvtColor(labeled_img, cv2.COLOR_HSV2BGR)\n",
    "        labeled_img[label_hue==0] = 0\n",
    "\n",
    "        cv2.imshow('label', labeled_img)\n",
    "        out.write(labeled_img)\n",
    "    ###############################################################\n",
    "\n",
    "    ret, match_dict = intersecting_regions(cur_img, cur_count, volume[-1], labels[-1])\n",
    "\n",
    "    cur_label = []\n",
    "\n",
    "    cur_img_output = cur_img.copy()\n",
    "\n",
    "    if ret is True:\n",
    "        # Some current region is intersecting with multiple previous regions\n",
    "\n",
    "        cur_img_copy = cur_img.copy()\n",
    "\n",
    "        # Erode the image to try and separate the regions\n",
    "        kernel = np.ones((5,5), np.uint8)\n",
    "        cur_img_copy = cv2.erode(cur_img_copy, kernel, iterations = 1)\n",
    "\n",
    "        cur_count_copy, cur_img_copy = cv2.connectedComponents(cur_img_copy, connectivity=8)\n",
    "\n",
    "        # Find the number of intersections using eroded image\n",
    "        ret, match_dict_copy = intersecting_regions(cur_img_copy, cur_count_copy, volume[-1], labels[-1])\n",
    "\n",
    "\n",
    "        print(\"intersection \" + str(ret) + str(match_dict_copy))\n",
    "\n",
    "        if ret is False:\n",
    "            print(\"erosion success\")\n",
    "            # The intersecting regions have been separated by erosion\n",
    "            # Replace the image by the eroded image\n",
    "            cur_img = cur_img_copy\n",
    "            cur_count = cur_count_copy\n",
    "            match_dict = match_dict_copy\n",
    "        else:\n",
    "            # The intersecting regions did not separate\n",
    "            # Overwrite matching labels in the volume with current label\n",
    "\n",
    "            tube_num += 1\n",
    "\n",
    "            for region in match_dict:\n",
    "                if len(match_dict[region]) > 1:\n",
    "\n",
    "                    for index in match_dict[region]:\n",
    "                        for frame in volume:\n",
    "                            # Update labels of tubes in previous frame\n",
    "#                             frame[frame == index] = tube_num\n",
    "                            # Add an entry to the overwrite dict\n",
    "                            overwrite_dict[index] = [tube_num]\n",
    "\n",
    "                    # Update the dict\n",
    "                    match_dict[region] = [tube_num]\n",
    "#                     cur_img[cur_img == region] = tube_num\n",
    "#                     cur_label.append(tube_num)\n",
    "\n",
    "                    \n",
    "\n",
    "\n",
    "    # There are no intersection issues; Proceed normally\n",
    "    for region in match_dict:\n",
    "        if len(match_dict[region]) == 0:\n",
    "            # New region found since there is no match to any previous region\n",
    "            tube_num += 1\n",
    "            cur_img_output[cur_img == region] = tube_num\n",
    "            cur_label.append(tube_num)\n",
    "\n",
    "        else:\n",
    "            # Some previous region was found, relabel the region\n",
    "            cur_img_output[cur_img == region] = match_dict[region][0]\n",
    "            cur_label.append(match_dict[region][0])\n",
    "    \n",
    "\n",
    "    volume.append(cur_img_output)\n",
    "#     print(cur_label)\n",
    "    labels.append(cur_label) # Convert keys in the match_dict to a list of labels of current image\n",
    "    prev_count = cur_count\n",
    "\n",
    "    k = cv2.waitKey(1) & 0xff\n",
    "    if k == 27:\n",
    "        break\n",
    "\n",
    "# Update previous frames\n",
    "# print(overwrite_dict)\n",
    "for index in overwrite_dict:\n",
    "    for frame in volume:\n",
    "        # Update labels of tubes in previous frame\n",
    "        frame[frame == index] = tube_num\n",
    "    \n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n",
    "print('done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tube_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0 20]\n",
      "[123857086   1284674]\n"
     ]
    }
   ],
   "source": [
    "uniq, __ = np.unique(volume, return_counts=True)\n",
    "print(uniq)\n",
    "print(__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(uniq)):\n",
    "    \n",
    "    out = cv2.VideoWriter('maskTube{0}.avi'.format(i),cv2.VideoWriter_fourcc('M','J','P','G'), 15, (frame_width,frame_height))\n",
    "    \n",
    "    for frame in volume:\n",
    "        frameCopy = frame.copy()\n",
    "        frameCopy[frameCopy==uniq[i]] = 255\n",
    "        frameCopy[frameCopy!=255] = 0\n",
    "        frameCopy = frameCopy.astype(np.uint8)\n",
    "        out.write(cv2.cvtColor(frameCopy, cv2.COLOR_GRAY2BGR))\n",
    "\n",
    "    out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
